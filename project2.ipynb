{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras, tensorflow\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "categories = [ 'incorrect_mask','with_mask' , 'without_mask']\n",
    "for i in categories: \n",
    "    path = os.path.join('train' , i )\n",
    "    label = categories.index(i) \n",
    "    for file in os.listdir(path):\n",
    "        #print(file)\n",
    "        img_path = os.path.join(path , file)\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img,(224,224))\n",
    "        data.append([img,label])       \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path = os.path.join('train' , 'with_mask' )\n",
    "# img_path = os.path.join(path , '0-with-mask.jpg')\n",
    "# print(img_path)\n",
    "# img = cv2.imread(img_path)\n",
    "# img = cv2.resize(img,(224,224))\n",
    "# cv2.imshow(\"image\",img)\n",
    "# cv2.waitKey(10000)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2079"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [] \n",
    "y = []\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2079"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2079, 224, 224, 3) (2079,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y= to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train, y_test = train_test_split( x , y , random_state= 0 , test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663, 224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   zoom_range=0.3,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   brightness_range=[0.4, 1.5],\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate batches of augmented data from the training array\n",
    "training_set = train_datagen.flow(x_train, y_train,\n",
    "                                  batch_size=32,\n",
    "                                  shuffle=True)\n",
    "\n",
    "# Generate batches of augmented data from the testing array\n",
    "test_set = test_datagen.flow(x_test, y_test,\n",
    "                             batch_size=32,\n",
    "                             shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "vgg =VGG16()\n",
    "vgg = VGG16(weights='imagenet', include_top=False,input_shape = (224,224,3))\n",
    "#vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000)\n"
     ]
    }
   ],
   "source": [
    "layer = vgg.layers[-1]\n",
    "print(layer.output_shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg.layers[: -1]:\n",
    "    model.add(layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "dropout1 = Dropout(0.1)\n",
    "dropout2 = Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = model.layers[-3]\n",
    "fc2 = model.layers[-2]\n",
    "predictions = model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "x = dropout1(fc1.output)\n",
    "x = fc2(x)\n",
    "x = dropout2(x)\n",
    "predictors = predictions(x)\n",
    "\n",
    "# Create a new model\n",
    "model2 = Model(inputs=model.input , outputs=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#freezing the parametre\n",
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 14, 14, 512)       14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 301059    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,015,747\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "final_model = Sequential()\n",
    "final_model.add(model2)\n",
    "final_model.add(Flatten())\n",
    "final_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#model2.add(Dense(1, activation='sigmoid'))\n",
    "final_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gyaneshwar\\AppData\\Local\\Temp\\ipykernel_20776\\814859723.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    }
   ],
   "source": [
    "tensorflow.test.is_gpu_available()\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "checkpoint = ModelCheckpoint(\"vgg16.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\n",
    "earlystop = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.1735 - accuracy: 0.7426\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95433, saving model to vgg16.h5\n",
      "52/52 [==============================] - 341s 7s/step - loss: 1.1735 - accuracy: 0.7426 - val_loss: 0.1484 - val_accuracy: 0.9543\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.8310\n",
      "Epoch 2: val_accuracy did not improve from 0.95433\n",
      "52/52 [==============================] - 397s 8s/step - loss: 0.5533 - accuracy: 0.8310 - val_loss: 0.2470 - val_accuracy: 0.9495\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8966\n",
      "Epoch 3: val_accuracy improved from 0.95433 to 0.96635, saving model to vgg16.h5\n",
      "52/52 [==============================] - 348s 7s/step - loss: 0.3485 - accuracy: 0.8966 - val_loss: 0.1147 - val_accuracy: 0.9663\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.9092\n",
      "Epoch 4: val_accuracy improved from 0.96635 to 0.98077, saving model to vgg16.h5\n",
      "52/52 [==============================] - 356s 7s/step - loss: 0.2780 - accuracy: 0.9092 - val_loss: 0.0799 - val_accuracy: 0.9808\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9188  \n",
      "Epoch 5: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 27209s 533s/step - loss: 0.2121 - accuracy: 0.9188 - val_loss: 0.1055 - val_accuracy: 0.9663\n",
      "Epoch 6/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9381\n",
      "Epoch 6: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 340s 7s/step - loss: 0.2006 - accuracy: 0.9381 - val_loss: 0.1042 - val_accuracy: 0.9736\n",
      "Epoch 7/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9308\n",
      "Epoch 7: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 366s 7s/step - loss: 0.2342 - accuracy: 0.9308 - val_loss: 0.1141 - val_accuracy: 0.9736\n",
      "Epoch 8/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9308\n",
      "Epoch 8: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 333s 6s/step - loss: 0.2209 - accuracy: 0.9308 - val_loss: 0.1146 - val_accuracy: 0.9663\n",
      "Epoch 9/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9333\n",
      "Epoch 9: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 354s 7s/step - loss: 0.2260 - accuracy: 0.9333 - val_loss: 0.1559 - val_accuracy: 0.9639\n",
      "Epoch 10/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9308\n",
      "Epoch 10: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 309s 6s/step - loss: 0.2274 - accuracy: 0.9308 - val_loss: 0.1124 - val_accuracy: 0.9760\n",
      "Epoch 11/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.9296\n",
      "Epoch 11: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 339s 7s/step - loss: 0.2732 - accuracy: 0.9296 - val_loss: 0.1197 - val_accuracy: 0.9784\n",
      "Epoch 12/15\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9465\n",
      "Epoch 12: val_accuracy did not improve from 0.98077\n",
      "52/52 [==============================] - 337s 6s/step - loss: 0.1874 - accuracy: 0.9465 - val_loss: 0.0999 - val_accuracy: 0.9760\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_model.compile( optimizer= 'Adam' , loss ='categorical_crossentropy' , metrics= ['accuracy'])\n",
    "#metrics=[ metrics.MeanSquaredError(), metrics.AUC()] \n",
    "#final_model.fit(x_train , y_train , epochs= 5 , validation_data=( x_test , y_test))\n",
    "batch_size = 32  # Specify the desired batch size\n",
    "\n",
    "\n",
    "History=final_model.fit(training_set, epochs=15, callbacks=[checkpoint,earlystop],validation_data=(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "img = cv2.imread(r\"C:\\Users\\Gyaneshwar\\Desktop\\Project 2\\test2.PNG\")\n",
    "if img is not None:\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Do something with the resized image\n",
    "    # ...\n",
    "\n",
    "else:\n",
    "    print(\"Failed to load the image\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_model.predict(resized_img.reshape(1,224,224,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[0][0])\n",
    "print(y_pred[0][1])\n",
    "print(y_pred[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_mask(img):\n",
    "     y_pred = model.predict(img.reshape(1,224,224,3))\n",
    "    # max_index = y_pred.index(max(y_pred[0]))\n",
    "     return y_pred\n",
    "     \n",
    "\n",
    "\n",
    "def draw_label(img ,text, pos, bg_color):\n",
    "    text_size =cv2.getTextSize(text , cv2.FONT_HERSHEY_COMPLEX,1 , cv2.FILLED)\n",
    "\n",
    "    end_x = pos[0] + text_size[0][1] + 2\n",
    "    end_y = pos[1] + text_size[0][1] - 2\n",
    "    cv2.rectangle(img,pos,(end_x , end_y), bg_color, cv2.FILLED)\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_COMPLEX , 1, (0,0,0),1,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 157ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  3.8900206  4.52857   44.820084 ]\n",
      " [ 0.         0.         0.        ...  0.         5.270244   1.3614038]\n",
      " [ 0.         0.         0.        ...  0.        43.368652   0.       ]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  4.850369   0.        38.97506  ]\n",
      " [ 0.         0.         0.        ...  0.         0.         1.7913667]\n",
      " [ 0.         0.         0.        ...  0.        39.811035   0.       ]]\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       30.009216]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       30.56057   0.      ]]\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  7.9053464  0.        39.580025 ]\n",
      " [ 0.         0.         0.        ...  0.         0.         5.521114 ]\n",
      " [ 0.         0.         0.        ...  0.        45.278774   0.       ]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  0.         1.3086722 26.882446 ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.        29.046822   0.       ]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       22.793648  0.      ]]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       31.235645  0.      ]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       10.247469]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       29.35057   0.      ]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       26.4652  ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       28.598593  0.      ]]\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        7.814517]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       28.499537  0.      ]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       16.398964]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       29.8951    0.      ]]\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "[[ 0.       0.       0.      ...  0.       0.       0.     ]\n",
      " [ 0.       0.       0.      ...  0.       0.       0.     ]\n",
      " [ 0.       0.       0.      ...  0.       0.       0.     ]\n",
      " ...\n",
      " [ 0.       0.       0.      ...  0.       0.      13.06306]\n",
      " [ 0.       0.       0.      ...  0.       0.       0.     ]\n",
      " [ 0.       0.       0.      ...  0.      29.57701  0.     ]]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       12.051032]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       24.441126  0.      ]]\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       12.805154]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       32.39218   0.      ]]\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  0.         0.         1.8761936]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.        29.147379   0.       ]]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       25.574974  0.      ]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       14.07983 ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       23.179781  0.      ]]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        8.770862]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       26.858688  0.      ]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       17.5297  ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       25.248903  0.      ]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       14.687173]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       28.119307  0.      ]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       16.318377]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       21.761072  0.      ]]\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.       22.905504]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       26.613503  0.      ]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  0.         3.8404734 37.156155 ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.        27.384502   0.       ]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  2.3188536  0.        36.55544  ]\n",
      " [ 0.         0.         0.        ...  0.         0.        14.428919 ]\n",
      " [ 0.         0.         0.        ...  0.        39.78403    0.       ]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         4.5889745 ... 20.4506     0.        47.631336 ]\n",
      " [ 0.         0.         0.        ...  0.         0.        27.670471 ]\n",
      " [ 0.         0.         0.        ...  0.        31.553045   0.       ]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ... 30.961185  0.       14.618423]\n",
      " [ 0.        0.        0.       ...  0.        0.        4.410759]\n",
      " [ 0.        0.        0.       ...  0.       37.421032  0.      ]]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ... 29.75854   0.       21.278988]\n",
      " [ 0.        0.        0.       ...  0.        0.        7.470752]\n",
      " [ 0.        0.        0.       ...  0.       36.13119   0.      ]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ... 20.013721  0.       20.719109]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       35.09403   0.      ]]\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ... 14.11594     0.\n",
      "  15.783621  ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.89751387]\n",
      " [ 0.          0.          0.         ...  0.         33.601307\n",
      "   0.        ]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ... 28.400654   0.         7.6635485]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.        31.499422   0.       ]]\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  8.169965  0.        8.871589]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       29.597528  0.      ]]\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ... 15.192825  0.       12.321587]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.       29.115751  0.      ]]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  5.8234982  0.        28.231937 ]\n",
      " [ 0.         0.         0.        ...  0.         0.         8.28727  ]\n",
      " [ 0.         0.         0.        ...  0.        33.496468   0.       ]]\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  6.7310867  0.        23.466103 ]\n",
      " [ 0.         0.         0.        ...  0.         0.         2.4151485]\n",
      " [ 0.         0.         0.        ...  0.        28.041695   0.       ]]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  5.435607   0.         6.5604067]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.        21.75364    0.       ]]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.       35.519646 ... 30.365503  0.       31.591875]\n",
      " [ 0.        0.        0.       ...  0.        0.        8.315681]\n",
      " [ 0.        0.        0.       ...  0.       36.040768  0.      ]]\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "[[  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " [  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " [  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " ...\n",
      " [  0.         0.         0.       ...  29.586065   0.        23.692886]\n",
      " [  0.         0.         0.       ...  77.279854   0.         0.      ]\n",
      " [  0.         0.         0.       ... 108.86008   11.408113   0.      ]]\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  5.7108555   0.\n",
      "  17.060623  ]\n",
      " [ 0.          0.          0.         ...  0.95435256  0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.         49.391403\n",
      "   0.        ]]\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  6.4925203  0.         0.       ]\n",
      " [ 0.         0.         0.        ...  6.4261565  3.0575864  0.       ]\n",
      " [ 0.         0.         0.        ...  0.        46.096466   0.       ]]\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  5.8558593   0.\n",
      "   1.326759  ]\n",
      " [ 0.          0.          0.         ...  0.15568224  2.4186456\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.         43.68566\n",
      "   0.        ]]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " ...\n",
      " [ 0.        0.        0.       ... 13.406393  0.        5.088043]\n",
      " [ 0.        0.        0.       ...  8.191042  6.322963  0.      ]\n",
      " [ 0.        0.        0.       ...  0.       47.23311   0.      ]]\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         7.7954526  0.       ]\n",
      " [ 0.         0.         0.        ...  0.        52.291557   0.       ]]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.        ...  0.         0.        20.88927  ]\n",
      " [ 0.         0.         0.        ...  0.         6.4969354  0.       ]\n",
      " [ 0.         0.         0.        ...  0.        53.646557   0.       ]]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  31.310343  ]\n",
      " [ 0.          0.          0.         ...  0.          1.0312593\n",
      "   0.90934885]\n",
      " [ 0.          0.          0.         ...  0.         48.246044\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "      ret , frame  = cap.read()\n",
    "      \n",
    "      img = cv2.resize(frame,(224,224))\n",
    "      y_pred = detect_face_mask(img)\n",
    "      print(y_pred[0][2])\n",
    "      #if(y_pred[0][2]>0.5):\n",
    "       #     draw_label(frame , \"NO MASK\" , (30,30) ,(0,0,0))\n",
    "      #if(y_pred[0][0]>0.51):\n",
    "      #      draw_label(frame , \"NOT PROPER MASK\" , (30,30) ,(0,0,0))\n",
    "      #else:\n",
    "       #     draw_label(frame , \"MASK\" , (30,30) ,(0,0,0))\n",
    "\n",
    "      coods  = face_sqaure(frame)\n",
    "      for x,y,w,h in coods:\n",
    "        cv2.rectangle(frame, (x,y),(x+w , y+h),(255,0,0) , 2)\n",
    "      cv2.imshow(\"Windows\", frame)\n",
    "      \n",
    "      \n",
    "      cv2.imshow(\"window\" , frame)\n",
    "      if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "         break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coods  = face_sqaure(frame)\n",
    "      for x,y,w,h in coods:\n",
    "        cv2.rectangle(frame, (x,y),(x+w , y+h),(255,0,0) , 2)\n",
    "      cv2.imshow(\"Windows\", frame)\n",
    "      \n",
    "      \n",
    "      cv2.imshow(\"window\" , frame)\n",
    "      if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "         break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def draw_label(img ,text, pos, bg_color):\n",
    "    text_size =cv2.getTextSize(text , cv2.FONT_HERSHEY_COMPLEX,1 , cv2.FILLED)\n",
    "\n",
    "    end_x = pos[0] + text_size[0][1] + 2\n",
    "    end_y = pos[1] + text_size[0][1] - 2\n",
    "    cv2.rectangle(img,pos,(end_x , end_y), bg_color, cv2.FILLED)\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_COMPLEX , 1, (0,0,0),1,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "def face_sqaure(img):\n",
    "    faces =[]\n",
    "    #img = cv2.resize(img,(224,224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = haar.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    #faces = haar.detectMultiScale(img, 1.0485258, 6)\n",
    "    #coods = haar.detectMultiScale(img) \n",
    "    \n",
    "    return faces\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    coods=[]\n",
    "    coods  = face_sqaure(frame)\n",
    "    for x,y,w,h in coods:\n",
    "        cv2.rectangle(frame, (x,y),(x+w , y+h),(255,0,0) , 2)\n",
    "    cv2.imshow(\"Windows\", frame)\n",
    "    if cv2.waitKey(1)  & 0xFF == ord('x'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b83a9a91db0831d8232c08e6218b5bb27018356980982b9f79f4f3a0e004c59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
